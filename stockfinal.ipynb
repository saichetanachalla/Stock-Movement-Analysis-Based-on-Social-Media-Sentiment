{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "620f0a80-85e8-4db4-a591-f29f75b672e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "REDDIT_CLIENT_ID = 'ijE6EIkzU1bQGXmRLn-7RQ'\n",
    "REDDIT_SECRET = 'ex7i5dJu9Y2PBldLKhG7sw9BW-5Wiw'\n",
    "REDDIT_USER_AGENT = 'StockPredictor v1.0 by /u/Similar_Earth1995'  \n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55b0ea6e-c5a1-4754-a814-eff8d2f78660",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_name = 'stocks' \n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "posts = subreddit.top(time_filter='month', limit=5000)  \n",
    "\n",
    "data = []\n",
    "for post in posts:\n",
    "    data.append({\n",
    "        'title': post.title,\n",
    "        'selftext': post.selftext,\n",
    "        'upvotes': post.score,\n",
    "        'comments': post.num_comments,\n",
    "        'created_utc': post.created_utc\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2f2251c-3c62-4dfd-8f34-b221210b59f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'reddit_posts_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('reddit_posts_data.csv', index=False)\n",
    "\n",
    "print(\"Data saved to 'reddit_posts_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26c433f-9c4b-4ecc-9e72-5c1b5d143bfb",
   "metadata": {},
   "source": [
    "Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d14bc8b-7916-4bcf-b13b-4110831a44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Challa Sai\n",
      "[nltk_data]     Chetana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Challa Sai\n",
      "[nltk_data]     Chetana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'reddit_cleaned_posts.csv'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)  # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stop words\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply cleaning\n",
    "df['cleaned_title'] = df['title'].apply(clean_text)\n",
    "df['cleaned_selftext'] = df['selftext'].apply(clean_text)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('reddit_cleaned_posts.csv', index=False)\n",
    "print(\"Cleaned data saved to 'reddit_cleaned_posts.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f240e73b-4a67-4eca-ae13-26733325c9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document-Term Matrix shape: (338, 692)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df['text'] = df['cleaned_title'] + ' ' + df['cleaned_selftext']\n",
    "\n",
    "# Use CountVectorizer to create a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=10, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "print(\"Document-Term Matrix shape:\", dtm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fecb4b3e-a6fb-47a8-8398-c34b31adf347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model Fitted!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Define the number of topics\n",
    "num_topics = 5\n",
    "\n",
    "# Fit LDA model\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "print(\"LDA Model Fitted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ce022f4-c738-4abd-b03d-74d01879cf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "potential share revenue ai data growth price stock company market\n",
      "\n",
      "Topic 2:\n",
      "shares know time think buy company im years like stock\n",
      "\n",
      "Topic 3:\n",
      "growth share earnings company quarter said year revenue million billion\n",
      "\n",
      "Topic 4:\n",
      "trump companies energy like sp tesla im market stocks stock\n",
      "\n",
      "Topic 5:\n",
      "including investopedia links aggregated options stocks daily fundamentals market news\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get feature names (words)\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display topics and their top words\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx + 1}:\")\n",
    "    print(\" \".join([words[i] for i in topic.argsort()[-10:]]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f9ff65b-2497-4733-bc95-345d4a46d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic modeling results saved to 'reddit_topic_modeling.csv'\n"
     ]
    }
   ],
   "source": [
    "# Get the topic distribution for each document\n",
    "doc_topic_matrix = lda.transform(dtm)\n",
    "\n",
    "# Assign the dominant topic for each document\n",
    "df['dominant_topic'] = doc_topic_matrix.argmax(axis=1)\n",
    "\n",
    "# Save the results\n",
    "df.to_csv('reddit_topic_modeling.csv', index=False)\n",
    "print(\"Topic modeling results saved to 'reddit_topic_modeling.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "990bba94-c13d-4994-8003-4ae73f2e3615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Elon Musk’s Trump bet has paid off so well tha...   \n",
      "1  If you could only buy one stock now what would...   \n",
      "2  Nvidia to join Dow Jones Industrial Average, r...   \n",
      "3        TSMC cannot make 2nm chips abroad now: MOEA   \n",
      "4  Warren Buffett’s Berkshire Hathaway sold ~$14 ...   \n",
      "\n",
      "                                            selftext  upvotes  comments  \\\n",
      "0  [https://fortune.com/2024/11/11/elon-musk-dona...     9728       763   \n",
      "1  \\nI have $2000 to invest. I’m stupid when it c...     1535      2433   \n",
      "2  Nvidia is replacing Intel on the Dow Jones Ind...     1177       135   \n",
      "3  Taiwan’s technology protection rules prohibits...     1049       250   \n",
      "4  Berkshires cash on hand hits a record $325 Bil...     1047       333   \n",
      "\n",
      "    created_utc                                      cleaned_title  \\\n",
      "0  1.731344e+09  elon musks trump bet paid well tesla worth res...   \n",
      "1  1.732735e+09                          could buy one stock would   \n",
      "2  1.730497e+09  nvidia join dow jones industrial average repla...   \n",
      "3  1.731021e+09                     tsmc make nm chips abroad moea   \n",
      "4  1.730550e+09  warren buffetts berkshire hathaway sold billio...   \n",
      "\n",
      "                                    cleaned_selftext  \\\n",
      "0  tesla ceo elon musks allin gamble get donald t...   \n",
      "1  invest im stupid comes stocks listen random st...   \n",
      "2  nvidia replacing intel dow jones industrial av...   \n",
      "3  taiwans technology protection rules prohibits ...   \n",
      "4  berkshires cash hand hits record billion curre...   \n",
      "\n",
      "                                                text  dominant_topic  \\\n",
      "0  elon musks trump bet paid well tesla worth res...               3   \n",
      "1  could buy one stock would invest im stupid com...               1   \n",
      "2  nvidia join dow jones industrial average repla...               0   \n",
      "3  tsmc make nm chips abroad moea taiwans technol...               2   \n",
      "4  warren buffetts berkshire hathaway sold billio...               2   \n",
      "\n",
      "  stock_movement  \n",
      "0             up  \n",
      "1             up  \n",
      "2           down  \n",
      "3           down  \n",
      "4           down  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('reddit_topic_modeling.csv')\n",
    "\n",
    "import numpy as np\n",
    "df['stock_movement'] = np.random.choice(['up', 'down'], size=len(df))\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "399d87ab-5f16-4887-86f9-00f16dbafcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded columns added!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['dominant_topic_encoded'] = encoder.fit_transform(df['dominant_topic'])\n",
    "df['stock_movement_encoded'] = encoder.fit_transform(df['stock_movement'])\n",
    "\n",
    "print(\"Encoded columns added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5085fbc6-4f20-43b0-8545-d5dc6a8a2dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['dominant_topic_encoded', 'upvotes', 'comments']]\n",
    "y = df['stock_movement_encoded']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b7ffd03-72f2-437d-9688-47ed05b695a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3fa746cc-3d40-4eea-8296-3ca2d452b2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58        36\n",
      "           1       0.52      0.50      0.51        32\n",
      "\n",
      "    accuracy                           0.54        68\n",
      "   macro avg       0.54      0.54      0.54        68\n",
      "weighted avg       0.54      0.54      0.54        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "977b863f-6a4b-49e3-9ecb-173861e54e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment scores added!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "df['sentiment_score'] = df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "print(\"Sentiment scores added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1285d76a-840d-4897-9a88-9c89dfc9cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic probabilities added!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Combine title and text\n",
    "df['text'] = df['cleaned_title'] + ' ' + df['cleaned_selftext']\n",
    "\n",
    "# Vectorize the text using CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.9, min_df=10, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Apply LDA\n",
    "num_topics = 5\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Add topic probabilities as features\n",
    "topic_probabilities = lda.transform(dtm)\n",
    "for i in range(num_topics):\n",
    "    df[f'topic_{i}_prob'] = topic_probabilities[:, i]\n",
    "\n",
    "print(\"Topic probabilities added!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "809158bc-130f-4e86-b431-9c4d26767b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE applied: Dataset is now balanced!\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['sentiment_score', 'topic_0_prob', 'topic_1_prob', 'topic_2_prob', 'topic_3_prob', 'topic_4_prob', 'upvotes', 'comments']]\n",
    "y = df['stock_movement_encoded']  # Assuming stock_movement_encoded is the target column\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"SMOTE applied: Dataset is now balanced!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a81dca3a-4295-40e1-9d70-d2a2b1dc10c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Data split into training and testing sets!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c33cce6-490b-4085-93d0-793857bd1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Challa Sai Chetana\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:44:19] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed!\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f877991-114f-457d-afcf-e0f34cfd0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.37      0.43        41\n",
      "           1       0.40      0.57      0.47        30\n",
      "\n",
      "    accuracy                           0.45        71\n",
      "   macro avg       0.47      0.47      0.45        71\n",
      "weighted avg       0.48      0.45      0.45        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9f4e393-f450-4138-995c-73a1f17efb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Challa Sai Chetana\\AppData\\Local\\Temp\\ipykernel_24712\\3742111384.py:19: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  for submission in subreddit.top('month', limit=5000):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk’s Trump bet has paid off so well tha...</td>\n",
       "      <td>[https://fortune.com/2024/11/11/elon-musk-dona...</td>\n",
       "      <td>9729</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you could only buy one stock now what would...</td>\n",
       "      <td>\\nI have $2000 to invest. I’m stupid when it c...</td>\n",
       "      <td>1540</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nvidia to join Dow Jones Industrial Average, r...</td>\n",
       "      <td>Nvidia is replacing Intel on the Dow Jones Ind...</td>\n",
       "      <td>1179</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSMC cannot make 2nm chips abroad now: MOEA</td>\n",
       "      <td>Taiwan’s technology protection rules prohibits...</td>\n",
       "      <td>1048</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Buffett’s Berkshire Hathaway sold ~$14 ...</td>\n",
       "      <td>Berkshires cash on hand hits a record $325 Bil...</td>\n",
       "      <td>1045</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Elon Musk’s Trump bet has paid off so well tha...   \n",
       "1  If you could only buy one stock now what would...   \n",
       "2  Nvidia to join Dow Jones Industrial Average, r...   \n",
       "3        TSMC cannot make 2nm chips abroad now: MOEA   \n",
       "4  Warren Buffett’s Berkshire Hathaway sold ~$14 ...   \n",
       "\n",
       "                                                text  upvotes  comments  \n",
       "0  [https://fortune.com/2024/11/11/elon-musk-dona...     9729       763  \n",
       "1  \\nI have $2000 to invest. I’m stupid when it c...     1540      2435  \n",
       "2  Nvidia is replacing Intel on the Dow Jones Ind...     1179       135  \n",
       "3  Taiwan’s technology protection rules prohibits...     1048       250  \n",
       "4  Berkshires cash on hand hits a record $325 Bil...     1045       333  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# Initialize Reddit API client\n",
    "REDDIT_CLIENT_ID = 'ijE6EIkzU1bQGXmRLn-7RQ'\n",
    "REDDIT_SECRET = 'ex7i5dJu9Y2PBldLKhG7sw9BW-5Wiw'\n",
    "REDDIT_USER_AGENT = 'StockPredictor v1.0 by /u/Similar_Earth1995'   # e.g., \"StockPredictorApp v1.0 by /u/your_username\"\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=REDDIT_CLIENT_ID,\n",
    "    client_secret=REDDIT_SECRET,\n",
    "    user_agent=REDDIT_USER_AGENT\n",
    ")\n",
    "\n",
    "# Define subreddit and fetch posts\n",
    "subreddit = reddit.subreddit('stocks')  # You can change this to a relevant subreddit\n",
    "posts = []\n",
    "\n",
    "# Scraping top 5000 posts from the last month\n",
    "for submission in subreddit.top('month', limit=5000):\n",
    "    posts.append([submission.title, submission.selftext, submission.score, submission.num_comments])\n",
    "\n",
    "# Convert posts into a DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(posts, columns=['title', 'text', 'upvotes', 'comments'])\n",
    "\n",
    "# Check the first few entries of the dataframe\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "378dddea-f857-4bc0-b15e-688b13c03e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text data: remove any non-alphabetical characters and lowercase everything\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce9277d8-5f6b-40a9-90d4-555bd710a5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>vader_sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>httpsfortunecomelonmuskdonaldtrumpelectiontesl...</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\ni have  to invest im stupid when it comes to...</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nvidia is replacing intel on the dow jones ind...</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taiwans technology protection rules prohibits ...</td>\n",
       "      <td>0.5118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>berkshires cash on hand hits a record  billion...</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_cleaned  vader_sentiment_score  \\\n",
       "0  httpsfortunecomelonmuskdonaldtrumpelectiontesl...                 0.8429   \n",
       "1  \\ni have  to invest im stupid when it comes to...                 0.4040   \n",
       "2  nvidia is replacing intel on the dow jones ind...                 0.8683   \n",
       "3  taiwans technology protection rules prohibits ...                 0.5118   \n",
       "4  berkshires cash on hand hits a record  billion...                 0.6808   \n",
       "\n",
       "   sentiment_label  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to get sentiment scores\n",
    "df['vader_sentiment_score'] = df['text_cleaned'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Assign labels based on sentiment\n",
    "df['sentiment_label'] = df['vader_sentiment_score'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Check the first few entries\n",
    "df[['text_cleaned', 'vader_sentiment_score', 'sentiment_label']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0f090309-41f4-4526-8444-c073b932fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize the cleaned text using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "X_tfidf = vectorizer.fit_transform(df['text_cleaned'])\n",
    "\n",
    "# Convert to DataFrame for ease of use\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afe73bad-39f7-402d-9020-3ee7a207718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_label\n",
      "1    285\n",
      "0    285\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Define target variable (sentiment label)\n",
    "y = df['sentiment_label']\n",
    "\n",
    "# Apply SMOTE for oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf_df, y)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(pd.Series(y_resampled).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0d685331-ec06-454c-8d33-12aa1ccfca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\challa sai chetana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\challa sai chetana\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.3/1.4 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "998fb72a-50b0-4154-b45f-80d736599cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 224, number of negative: 232\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7700\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 505\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491228 -> initscore=-0.035091\n",
      "[LightGBM] [Info] Start training from score -0.035091\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy (LightGBM): 0.9210526315789473\n",
      "Classification Report (LightGBM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91        53\n",
      "           1       0.88      0.98      0.93        61\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.92      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LightGBM model\n",
    "model_lgb = lgb.LGBMClassifier(random_state=42, is_unbalance=True)\n",
    "model_lgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lgb = model_lgb.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy (LightGBM):\", accuracy_score(y_test, y_pred_lgb))\n",
    "print(\"Classification Report (LightGBM):\")\n",
    "print(classification_report(y_test, y_pred_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fd4b80e-e3ff-44d4-a73c-4b2a21d9ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 228, number of negative: 228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8068\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 516\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 228, number of negative: 228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7455\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 497\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 228, number of negative: 228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7063\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 458\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 228, number of negative: 228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7742\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 493\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 228, number of negative: 228\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7350\n",
      "[LightGBM] [Info] Number of data points in the train set: 456, number of used features: 485\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Cross-Validation F1 Score: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation to check consistency of the best model\n",
    "cv_scores = cross_val_score(best_model, X_resampled, y_resampled, cv=5, scoring='f1_weighted')\n",
    "print(f\"Cross-Validation F1 Score: {cv_scores.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39340a-3180-482a-86b4-4a12b8afa284",
   "metadata": {},
   "source": [
    "Light bgm model gave more accuracy compared to xgboost and randomforest which is 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cc365-76a8-4a49-915f-2339dea067b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
